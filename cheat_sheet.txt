#### Download Datasets ####
cd /mnts/deepliif-data
mkdir DeepLIIF_Datasets
cd DeepLIIF_Datasets
wget https://zenodo.org/record/4751737/files/DeepLIIF_Training_Set.zip
wget https://zenodo.org/record/4751737/files/DeepLIIF_Validation_Set.zip
wget https://zenodo.org/record/4751737/files/DeepLIIF_Testing_Set.zip

unzip DeepLIIF_Training_Set.zip
unzip DeepLIIF_Validation_Set.zip
unzip DeepLIIF_Testing_Set.zip
rm -rf DeepLIIF_*.zip

mv DeepLIIF_Training_Set train
mv DeepLIIF_Validation_Set val
mv DeepLIIF_Testing_Set test

cd train; ls -t1 | tail -n +100 | xargs rm -r; cd ../
cd val; ls -t1 | tail -n +100 | xargs rm -r; cd ../
cd test; ls -t1 | tail -n +100 | xargs rm -r; cd ../



# ------------------------------------------------------------------------------------------------



#### WS DP 1 GPU #### PASS
python cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model_wendy_ws --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --checkpoints-dir /mnts/DeepLIIFData/deepliif-ws-output

python run_visualizer_local.py --pickle_dir /mnts/DeepLIIFData/deepliif-ws-output/Test_Model_wendy_ws/pickle

#### WS DDP 1 worker single gpu #### PASS
torchrun -t 3 --log_dir /userfs/log/ --nproc_per_node 1 cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model_wendy_ws --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --checkpoints-dir /mnts/DeepLIIFData/deepliif-ws-output

python run_visualizer_local.py --pickle_dir /mnts/DeepLIIFData/deepliif-ws-output/Test_Model_wendy_ws/pickle


#### WMLA PyTorch 1 worker single gpu #### PASS
python cli.py train --dataroot {root_folder} --name Test_Model_wendy_wmla --remote True --remote-transfer-cmd custom_save.save_to_storage_volume --batch-size 3 --gpu-ids 0 --display-env $APP_ID

!python dlicmd.py --exec-start PyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \
                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=https://daell-wmla.datascienceelite.com \
                  --workerDeviceNum 1 --workerMemory 8g \
                  --model-dir $DIR_job_submission --model-main train_command.py \
                  --cs-datastore-meta type=fs,data_path=DeepLIIF_Datasets/

python run_visualizer_local.py --pickle_dir /mnts/DeepLIIFData/checkpoints/Test_Model_wendy_wmla/pickle

#### WMLA distPyTorch 1 worker single gpu #### PASS
!python dlicmd.py --exec-start distPyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \
                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=https://daell-wmla.datascienceelite.com \
                  --numWorker 1 --workerMemory 8g \
                  --model-dir $DIR_job_submission --model-main train_command.py \
                  --cs-datastore-meta type=fs,data_path=DeepLIIF_Datasets_Full/

python run_visualizer_local.py --pickle_dir /mnts/deepliif-data/checkpoints/pickle



#### WS DP 2 GPUs #### PASS
python train.py --dataroot /mnts/deepliif-data/DeepLIIF_Datasets/ --name Test_Model --model DeepLIIF --gpu_ids 0,1 --remote True --checkpoints_dir /mnts/deepliif-data/deepliif-ws-output --batch_size 4

python run_visualizer_local.py --pickle_dir /mnts/deepliif-data/deepliif-ws-output/Test_Model/pickle

#### WS DDP 2 workers single gpu #### PASS
torchrun -t 3 --log_dir /userfs/log/ --nproc_per_node 2 train.py --dataroot /mnts/deepliif-data/DeepLIIF_Datasets/ --name ws-20220103-num_threads0-batch_size2-num_workers2 --model DeepLIIF --checkpoints_dir /mnts/deepliif-data/deepliif-ws-output/ --batch_size 2  --remote True

python run_visualizer_local.py --pickle_dir /mnts/deepliif-data/deepliif-ws-output/ws-20220103-num_threads0-batch_size2-num_workers2/pickle --n_proc 2


#### WMLA PyTorch 1 worker 2 gpus #### PASS
!python dlicmd.py --exec-start PyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \
                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=https://daell-wmla.datascienceelite.com \
                  --workerDeviceNum 2 --workerMemory 8g \
                  --model-dir $DIR_job_submission --model-main train_command.py \
                  --cs-datastore-meta type=fs,data_path=DeepLIIF_Datasets/

python run_visualizer_local.py --pickle_dir /mnts/deepliif-data/checkpoints/pickle

#### WMLA distPyTorch 2 workers single gpu #### PASS
!python dlicmd.py --exec-start distPyTorch --rest-host $HOST --rest-port -1 --jwt-token $USER_ACCESS_TOKEN \
                  --msd-env USER_ACCESS_TOKEN=$USER_ACCESS_TOKEN --msd-env BASE_URL=https://daell-wmla.datascienceelite.com \
                  --numWorker 2 --workerMemory 8g \
                  --model-dir $DIR_job_submission --model-main train_command.py \
                  --cs-datastore-meta type=fs,data_path=DeepLIIF_Datasets_Full/

python run_visualizer_local.py --pickle_dir /mnts/deepliif-data/checkpoints/pickle  --n_proc 2


# ------------------------------------------------------------------------------------------------




deterministic training

#### WS DP GPUx1 #### PASS
python cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --seed 0 --print-freq 1

(epoch: 0, iters: 3, time: 0.673, data: 0.118) G_GAN_1: 0.973 G_L1_1: 26.864 D_real_1: 1.016 D_fake_1: 0.691 G_GAN_2: 0.905 G_L1_2: 18.429 D_real_2: 0.873 D_fake_2: 0.794 G_GAN_3: 0.858 G_L1_3: 41.366 D_real_3: 0.951 D_fake_3: 0.709 G_GAN_4: 0.878 G_L1_4: 73.108 D_real_4: 1.102 D_fake_4: 0.631 G_GAN_5: 10.136 G_L1_5: 51.323 D_real_5: 1.151 D_fake_5: 0.311 


#### WS DP GPUx2 #### SMALL VARIATION
python cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --gpu-ids 1 --seed 0 --print-freq 1

(epoch: 0, iters: 3, time: 1.575, data: 0.093) G_GAN_1: 0.934 G_L1_1: 26.955 D_real_1: 1.016 D_fake_1: 0.690 G_GAN_2: 0.840 G_L1_2: 18.482 D_real_2: 0.871 D_fake_2: 0.789 G_GAN_3: 0.860 G_L1_3: 41.322 D_real_3: 0.952 D_fake_3: 0.714 G_GAN_4: 0.864 G_L1_4: 73.129 D_real_4: 1.102 D_fake_4: 0.626 G_GAN_5: 8.634 G_L1_5: 51.329 D_real_5: 1.155 D_fake_5: 0.300 

(epoch: 0, iters: 3, time: 1.691, data: 0.100) G_GAN_1: 0.850 G_L1_1: 33.248 D_real_1: 0.913 D_fake_1: 0.692 G_GAN_2: 0.825 G_L1_2: 32.520 D_real_2: 0.795 D_fake_2: 0.810 G_GAN_3: 0.838 G_L1_3: 50.641 D_real_3: 0.870 D_fake_3: 0.796 G_GAN_4: 0.815 G_L1_4: 71.639 D_real_4: 0.969 D_fake_4: 0.646 G_GAN_5: 6.705 G_L1_5: 52.737 D_real_5: 1.105 D_fake_5: 0.204 



https://discuss.pytorch.org/t/reproducibility-over-multigpus-is-impossible-until-randomness-of-threads-is-controled-and-yet/47079/7


#### WS DDP GPUx1 #### PASS
torchrun -t 3 --log /userfs/log/ --nproc_per_node 1 cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --seed 0 --print-freq 1

[default0]:(epoch: 0, iters: 3, time: 0.678, data: 0.098) G_GAN_1: 1.073 G_L1_1: 27.205 D_real_1: 1.010 D_fake_1: 0.693 G_GAN_2: 1.197 G_L1_2: 18.859 D_real_2: 0.874 D_fake_2: 0.789 G_GAN_3: 0.836 G_L1_3: 41.954 D_real_3: 0.943 D_fake_3: 0.722 G_GAN_4: 0.936 G_L1_4: 71.545 D_real_4: 1.068 D_fake_4: 0.627 G_GAN_5: 7.346 G_L1_5: 51.339 D_real_5: 1.149 D_fake_5: 0.303


#### WS DDP GPUx2 #### PASS
torchrun -t 3 --log /userfs/log/ --nproc_per_node 2 cli.py train --dataroot /mnts/DeepLIIFData/DeepLIIF_Datasets/ --name Test_Model --batch-size 3 --num-threads 0 --remote True --gpu-ids 0 --gpu-ids 1 --seed 0 --print-freq 1

[default1]:(epoch: 0, iters: 3, time: 0.704, data: 0.122) G_GAN_1: 1.040 G_L1_1: 28.298 D_real_1: 0.790 D_fake_1: 0.924 G_GAN_2: 1.016 G_L1_2: 41.070 D_real_2: 0.645 D_fake_2: 1.100 G_GAN_3: 1.290 G_L1_3: 55.502 D_real_3: 1.094 D_fake_3: 0.614 G_GAN_4: 0.768 G_L1_4: 38.655 D_real_4: 0.777 D_fake_4: 0.880 G_GAN_5: 7.985 G_L1_5: 49.894 D_real_5: 2.621 D_fake_5: 0.537 
[default0]:(epoch: 0, iters: 3, time: 0.703, data: 0.126) G_GAN_1: 1.144 G_L1_1: 26.984 D_real_1: 1.009 D_fake_1: 0.690 G_GAN_2: 1.381 G_L1_2: 18.777 D_real_2: 0.861 D_fake_2: 0.789 G_GAN_3: 0.805 G_L1_3: 41.580 D_real_3: 0.944 D_fake_3: 0.721 G_GAN_4: 1.148 G_L1_4: 71.498 D_real_4: 1.078 D_fake_4: 0.633 G_GAN_5: 5.978 G_L1_5: 51.374 D_real_5: 1.141 D_fake_5: 0.336 
[default0]:Remote mode, snapshot refreshed: plot_current_losses.pickle, epoch: 0, counter_ratio: 0.004231311706629055


#### WMLA DP GPUx1 #### PASS
subprocess.run(f'python cli.py train --dataroot {root_folder} --name Test_Model --remote True --remote-transfer-cmd custom_save.save_to_storage_volume --batch-size 3 --gpu-ids 0 --seed 0 --print-freq 1 --display-env $APP_ID',shell=True)

(epoch: 0, iters: 3, time: 0.722, data: 0.484) G_GAN_1: 0.991 G_L1_1: 26.873 D_real_1: 1.008 D_fake_1: 0.689 G_GAN_2: 0.944 G_L1_2: 18.427 D_real_2: 0.866 D_fake_2: 0.797 G_GAN_3: 0.864 G_L1_3: 41.353 D_real_3: 0.949 D_fake_3: 0.711 G_GAN_4: 0.892 G_L1_4: 73.081 D_real_4: 1.101 D_fake_4: 0.635 G_GAN_5: 9.633 G_L1_5: 51.323 D_real_5: 1.143 D_fake_5: 0.303 


#### WMLA DDP GPUx1 #### PASS

(epoch: 0, iters: 3, time: 0.835, data: 0.481) G_GAN_1: 1.181 G_L1_1: 27.170 D_real_1: 1.002 D_fake_1: 0.699 G_GAN_2: 1.165 G_L1_2: 18.869 D_real_2: 0.863 D_fake_2: 0.791 G_GAN_3: 0.855 G_L1_3: 41.938 D_real_3: 0.932 D_fake_3: 0.720 G_GAN_4: 0.905 G_L1_4: 71.560 D_real_4: 1.078 D_fake_4: 0.621 G_GAN_5: 6.382 G_L1_5: 51.351 D_real_5: 1.161 D_fake_5: 0.330 


#### WMLA DDP GPUx2 #### PASS
(epoch: 0, iters: 3, time: 0.823, data: 0.535) G_GAN_1: 1.176 G_L1_1: 26.936 D_real_1: 1.004 D_fake_1: 0.685 G_GAN_2: 1.335 G_L1_2: 18.787 D_real_2: 0.857 D_fake_2: 0.789 G_GAN_3: 0.803 G_L1_3: 41.566 D_real_3: 0.938 D_fake_3: 0.717 G_GAN_4: 1.116 G_L1_4: 71.457 D_real_4: 1.065 D_fake_4: 0.630 G_GAN_5: 6.401 G_L1_5: 51.387 D_real_5: 1.152 D_fake_5: 0.341 
(epoch: 0, iters: 3, time: 0.784, data: 0.648) G_GAN_1: 0.996 G_L1_1: 28.346 D_real_1: 0.778 D_fake_1: 0.934 G_GAN_2: 1.030 G_L1_2: 41.046 D_real_2: 0.651 D_fake_2: 1.106 G_GAN_3: 1.411 G_L1_3: 55.510 D_real_3: 1.088 D_fake_3: 0.607 G_GAN_4: 0.763 G_L1_4: 38.651 D_real_4: 0.781 D_fake_4: 0.880 G_GAN_5: 8.759 G_L1_5: 49.885 D_real_5: 2.603 D_fake_5: 0.545 


#---------------------------------------------


