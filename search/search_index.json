{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Deep-Learning Inferred Multiplex Immunofluorescence for IHC Image Quantification Read Link | Cloud Deployment | Docker | Report Bug | Image.sc Forum Reporting biomarkers assessed by routine immunohistochemical (IHC) staining of tissue is broadly used in diagnostic pathology laboratories for patient care. To date, clinical reporting is predominantly qualitative or semi-quantitative. By creating a multitask deep learning framework referred to as DeepLIIF, we present a single-step solution to stain deconvolution/separation, cell segmentation, and quantitative single-cell IHC scoring. Leveraging a unique de novo dataset of co-registered IHC and multiplex immunofluorescence (mpIF) staining of the same slides, we segment and translate low-cost and prevalent IHC slides to more expensive-yet-informative mpIF images, while simultaneously providing the essential ground truth for the superimposed brightfield IHC channels. Moreover, a new nuclear-envelop stain, LAP2beta, with high (>95%) cell coverage is introduced to improve cell delineation/segmentation and protein expression quantification on IHC slides. By simultaneously translating input IHC images to clean/separated mpIF channels and performing cell segmentation/classification, we show that our model trained on clean IHC Ki67 data can generalize to more noisy and artifact-ridden images as well as other nuclear and non-nuclear markers such as CD3, CD8, BCL2, BCL6, MYC, MUM1, CD10, and TP53. We thoroughly evaluate our method on publicly available benchmark datasets as well as against pathologists' semi-quantitative scoring. \u00a9 This code is made available for non-commercial academic purposes. Overview of DeepLIIF pipeline and sample input IHCs (different brown/DAB markers -- BCL2, BCL6, CD10, CD3/CD8, Ki67) with corresponding DeepLIIF-generated hematoxylin/mpIF modalities and classified (positive (red) and negative (blue) cell) segmentation masks. (a) Overview of DeepLIIF. Given an IHC input, our multitask deep learning framework simultaneously infers corresponding Hematoxylin channel, mpIF DAPI, mpIF protein expression (Ki67, CD3, CD8, etc.), and the positive/negative protein cell segmentation, baking explainability and interpretability into the model itself rather than relying on coarse activation/attention maps. In the segmentation mask, the red cells denote cells with positive protein expression (brown/DAB cells in the input IHC), whereas blue cells represent negative cells (blue cells in the input IHC). (b) Example DeepLIIF-generated hematoxylin/mpIF modalities and segmentation masks for different IHC markers. DeepLIIF, trained on clean IHC Ki67 nuclear marker images, can generalize to noisier as well as other IHC nuclear/cytoplasmic marker images.","title":"Home"},{"location":"ImageJ/","text":"DeepLIIF ImageJ Plugin This is a plugin for ImageJ which allows users to easily submit images to DeepLIIF for IHC quantification. Installing the DeepLIIF Plugin Download DeepLIIF_ImageJ.jar from Zenodo (or build it using the instructions below). Open ImageJ and navigate to the Plugins > Install... menu item. Select the DeepLIIF_ImageJ.jar file. Install it into the ImageJ/plugins directory. Using the DeepLIIF Plugin Open an image file in ImageJ. If desired, select a region of interest to process. Otherwise, the entire image will be processed. (Note: DeepLIIF currently has a limit on image dimensions of 3000 x 3000 pixels.) Navigate to the Plugins > DeepLIIF > Submit Image to DeepLIIF menu item. Choose the resolution/magnification of your image ( 10x , 20x , or 40x ) and click OK . The image will be sent to the DeepLIIF server for processing. This can take several seconds or more, depending on the image size. The resulting inferred images and IHC scoring will be stored in a folder in the same directory as the original image. This folder is numbered, so that multiple runs on the same image (or regions of the image) will not overwrite previous results. The classification overlay image and IHC score are displayed. If desired, interactive adjustment can be performed on this result before the image or score windows are closed. Navigate to the Plugins > DeepLIIF > Adjust DeepLIIF Results menu item. Adjust the two sliders to change to segmentation threshold and size gating as desired. As the sliders are adjusted, the image will update to preview the results. The segmentation threshold adjusts how the generated probability map is used to classify the pixels as positive or negative. Size gating allows smaller cells to be omitted from the final results. When satisfied with the settings, click OK to send the images to the DeepLIIF server for processing. This can take several seconds or more, depending on the image size. The updated classification images and IHC scoring are written to their corresponding files. The updated classification overlay image and IHC score are displayed. Further adjustments can be made if desired, repeating steps 7-10, until the result image and score windows are closed. Using the DeepLIIF Plugin for Multiple ROIs Open an image file in ImageJ. Create the desired regions of interest and add them to ImageJ's ROI Manager. (Note: DeepLIIF currently has a limit on ROI dimensions of 3000 x 3000 pixels.) Navigate to the Plugins > DeepLIIF > Submit ROIs to DeepLIIF menu item. Choose the resolution/magnification of your image ( 10x , 20x , or 40x ) and click OK . The ROIs will be sent to the DeepLIIF server for processing. This can take several seconds or more, depending on the ROI sizes. The resulting inferred ROI images and IHC scoring will be stored in folders in the same directory as the original image. The classification overlay regions and combined IHC score are displayed. If desired, interactive adjustment can be performed on this result before the image or score windows are closed. Navigate to the Plugins > DeepLIIF > Adjust DeepLIIF Results menu item. Adjust the two sliders to change to segmentation threshold and size gating as desired. As the sliders are adjusted, the image will update to preview the results. The segmentation threshold adjusts how the generated probability map is used to classify the pixels as positive or negative. Size gating allows smaller cells to be omitted from the final results. When satisfied with the settings, click OK to send the ROIs to the DeepLIIF server for processing. This can take several seconds or more, depending on the ROI sizes. The updated classification ROI images and IHC scoring are written to their corresponding files. The updated classification overlay regions and IHC score are displayed. Further adjustments can be made if desired, repeating steps 7-10, until the result image and score windows are closed. Building the DeepLIIF Plugin Make sure that you have Maven installed. From this ImageJ_Plugin directory, run mvn package . Upon successful compilation, the file DeepLIIF_ImageJ.jar will be created.","title":"ImageJ Plugin"},{"location":"ImageJ/#deepliif-imagej-plugin","text":"This is a plugin for ImageJ which allows users to easily submit images to DeepLIIF for IHC quantification.","title":"DeepLIIF ImageJ Plugin"},{"location":"ImageJ/#installing-the-deepliif-plugin","text":"Download DeepLIIF_ImageJ.jar from Zenodo (or build it using the instructions below). Open ImageJ and navigate to the Plugins > Install... menu item. Select the DeepLIIF_ImageJ.jar file. Install it into the ImageJ/plugins directory.","title":"Installing the DeepLIIF Plugin"},{"location":"ImageJ/#using-the-deepliif-plugin","text":"Open an image file in ImageJ. If desired, select a region of interest to process. Otherwise, the entire image will be processed. (Note: DeepLIIF currently has a limit on image dimensions of 3000 x 3000 pixels.) Navigate to the Plugins > DeepLIIF > Submit Image to DeepLIIF menu item. Choose the resolution/magnification of your image ( 10x , 20x , or 40x ) and click OK . The image will be sent to the DeepLIIF server for processing. This can take several seconds or more, depending on the image size. The resulting inferred images and IHC scoring will be stored in a folder in the same directory as the original image. This folder is numbered, so that multiple runs on the same image (or regions of the image) will not overwrite previous results. The classification overlay image and IHC score are displayed. If desired, interactive adjustment can be performed on this result before the image or score windows are closed. Navigate to the Plugins > DeepLIIF > Adjust DeepLIIF Results menu item. Adjust the two sliders to change to segmentation threshold and size gating as desired. As the sliders are adjusted, the image will update to preview the results. The segmentation threshold adjusts how the generated probability map is used to classify the pixels as positive or negative. Size gating allows smaller cells to be omitted from the final results. When satisfied with the settings, click OK to send the images to the DeepLIIF server for processing. This can take several seconds or more, depending on the image size. The updated classification images and IHC scoring are written to their corresponding files. The updated classification overlay image and IHC score are displayed. Further adjustments can be made if desired, repeating steps 7-10, until the result image and score windows are closed.","title":"Using the DeepLIIF Plugin"},{"location":"ImageJ/#using-the-deepliif-plugin-for-multiple-rois","text":"Open an image file in ImageJ. Create the desired regions of interest and add them to ImageJ's ROI Manager. (Note: DeepLIIF currently has a limit on ROI dimensions of 3000 x 3000 pixels.) Navigate to the Plugins > DeepLIIF > Submit ROIs to DeepLIIF menu item. Choose the resolution/magnification of your image ( 10x , 20x , or 40x ) and click OK . The ROIs will be sent to the DeepLIIF server for processing. This can take several seconds or more, depending on the ROI sizes. The resulting inferred ROI images and IHC scoring will be stored in folders in the same directory as the original image. The classification overlay regions and combined IHC score are displayed. If desired, interactive adjustment can be performed on this result before the image or score windows are closed. Navigate to the Plugins > DeepLIIF > Adjust DeepLIIF Results menu item. Adjust the two sliders to change to segmentation threshold and size gating as desired. As the sliders are adjusted, the image will update to preview the results. The segmentation threshold adjusts how the generated probability map is used to classify the pixels as positive or negative. Size gating allows smaller cells to be omitted from the final results. When satisfied with the settings, click OK to send the ROIs to the DeepLIIF server for processing. This can take several seconds or more, depending on the ROI sizes. The updated classification ROI images and IHC scoring are written to their corresponding files. The updated classification overlay regions and IHC score are displayed. Further adjustments can be made if desired, repeating steps 7-10, until the result image and score windows are closed.","title":"Using the DeepLIIF Plugin for Multiple ROIs"},{"location":"ImageJ/#building-the-deepliif-plugin","text":"Make sure that you have Maven installed. From this ImageJ_Plugin directory, run mvn package . Upon successful compilation, the file DeepLIIF_ImageJ.jar will be created.","title":"Building the DeepLIIF Plugin"},{"location":"cloud/","text":"Cloud Deployment If you don't have access to GPU or appropriate hardware and don't want to install ImageJ, we have also created a cloud-native DeepLIIF deployment with a user-friendly interface to upload images, visualize, interact, and download the final results. DeepLIIF can also be accessed programmatically through an endpoint by posting a multipart-encoded request containing the original image file: POST /api/infer Parameters img (required) file: image to run the models on resolution string: resolution used to scan the slide (10x, 20x, 40x), defaults to 20x pil boolean: if true, use PIL.Image.open() to load the image, instead of python-bioformats slim boolean: if true, return only the segmentation result image For example, in Python: import os import json import base64 from io import BytesIO import requests from PIL import Image # Use the sample images from the main DeepLIIF repo images_dir = './Sample_Large_Tissues' filename = 'ROI_1.png' res = requests.post( url='https://deepliif.org/api/infer', files={ 'img': open(f'{images_dir}/{filename}', 'rb') }, # optional param that can be 10x, 20x (default) or 40x params={ 'resolution': '20x' } ) data = res.json() def b64_to_pil(b): return Image.open(BytesIO(base64.b64decode(b.encode()))) for name, img in data['images'].items(): output_filepath = f'{images_dir}/{os.path.splitext(filename)[0]}_{name}.png' with open(output_filepath, 'wb') as f: b64_to_pil(img).save(f, format='PNG') print(json.dumps(data['scoring'], indent=2)) Auto-scaling the service DeepLIIFs underlying infrastructure is completely defined using Pulumi stacks. Behind the scenes, we use containers to deploy both the web application and the API on top of an ECS cluster with an auto-scaling group that runs on G4dns (GPU) machines. Under stress, the system will autoscale both the compute capacity and the service availability to accommodate the incoming requests without affecting the overall performance. The current auto-scaling policy monitors the number of requests per target on the application load balancer.","title":"Cloud Deployment"},{"location":"cloud/#cloud-deployment","text":"If you don't have access to GPU or appropriate hardware and don't want to install ImageJ, we have also created a cloud-native DeepLIIF deployment with a user-friendly interface to upload images, visualize, interact, and download the final results. DeepLIIF can also be accessed programmatically through an endpoint by posting a multipart-encoded request containing the original image file: POST /api/infer Parameters img (required) file: image to run the models on resolution string: resolution used to scan the slide (10x, 20x, 40x), defaults to 20x pil boolean: if true, use PIL.Image.open() to load the image, instead of python-bioformats slim boolean: if true, return only the segmentation result image For example, in Python: import os import json import base64 from io import BytesIO import requests from PIL import Image # Use the sample images from the main DeepLIIF repo images_dir = './Sample_Large_Tissues' filename = 'ROI_1.png' res = requests.post( url='https://deepliif.org/api/infer', files={ 'img': open(f'{images_dir}/{filename}', 'rb') }, # optional param that can be 10x, 20x (default) or 40x params={ 'resolution': '20x' } ) data = res.json() def b64_to_pil(b): return Image.open(BytesIO(base64.b64decode(b.encode()))) for name, img in data['images'].items(): output_filepath = f'{images_dir}/{os.path.splitext(filename)[0]}_{name}.png' with open(output_filepath, 'wb') as f: b64_to_pil(img).save(f, format='PNG') print(json.dumps(data['scoring'], indent=2))","title":"Cloud Deployment"},{"location":"cloud/#auto-scaling-the-service","text":"DeepLIIFs underlying infrastructure is completely defined using Pulumi stacks. Behind the scenes, we use containers to deploy both the web application and the API on top of an ECS cluster with an auto-scaling group that runs on G4dns (GPU) machines. Under stress, the system will autoscale both the compute capacity and the service availability to accommodate the incoming requests without affecting the overall performance. The current auto-scaling policy monitors the number of requests per target on the application load balancer.","title":"Auto-scaling the service"},{"location":"deployment/","text":"Docker We provide a Dockerfile that can be used to run the DeepLIIF models inside a container. First, you need to install the Docker Engine . After installing the Docker, you need to follow these steps: Download the pretrained model and place them in DeepLIIF/checkpoints/DeepLIIF_Latest_Model. Change XXX of the WORKDIR line in the DockerFile to the directory containing the DeepLIIF project. To create a docker image from the docker file: docker build -t cuda/deepliif . The image is then used as a base. You can copy and use it to run an application. The application needs an isolated environment in which to run, referred to as a container. To create and run a container: docker run -it -v `pwd`:`pwd` -w `pwd` cuda/deepliif deepliif test --input-dir Sample_Large_Tissues When you run a container from the image, the deepliif CLI will be available. You can easily run any CLI command in the activated environment and copy the results from the docker container to the host. Dask deployment By default, DeepLIIF networks are deployed using a combination of TorchScript and Dask. Torchscript is used to serialize and optimize the models starting from a pre-trained model checkpoint and the Python code that describes the models. For more details check out the Serialize Model section on the documentation. Models parallelization and interdependencies are expressed using Dask Delayed functions that allow us to build a computational graph with minimal code annotations. The concrete implementation can be found on the run_dask() function under the deepliif.models module. Torchserve deployment This section describes how to run DeepLIIF's inference using Torchserve workflows. Workflows con be composed by both PyTorch models and Python functions that can be connected through a DAG. For DeepLIIF there are 4 main stages (see Figure 3): Pre-process deserialize the image from the request and return a tensor created from it. G1-4 run the ResNets to generate the Hematoxylin, DAPI, LAP2 and Ki67 masks. G51-5 run the UNets and apply Weighted Average to generate the Segmentation image. Aggregate aggregate and serialize the results and return to user. Composition of DeepLIIF nets into a Torchserve workflow. In practice, users need to call this workflow for each tile generated from the original image. A common use case scenario would be: Load an IHC image and generate the tiles. For each tile: Resize to 512x512 and transform to tensor. Serialize the tensor and use the inference API to generate all the masks. Deserialize the results. Stitch back the results and apply post-processing operations. The next sections show how to deploy the model server. Prerequisites 1. Install Torchserve and torch-model-archiver following these instructions . In MacOS, navigate to the model-server directory: cd model-server python3 -m venv venv source venv/bin/activate pip install torch torchserve torch-model-archiver torch-workflow-archiver 2. Download and unzip the latest version of the DeepLIIF models from zenodo . wget https://zenodo.org/record/4751737/files/DeepLIIF_Latest_Model.zip unzip DeepLIIF_Latest_Model.zip Package models and workflow In order to run the DeepLIIF nets using Torchserve, they first need to be archived as MAR files. In this section we will create the model artifacts and archive them in the model store. First, inside model-server create a directory to store the models. mkdir model-store For every ResNet ( G1 , G2 , G3 , G4 ) run replacing the name of the net: torch-model-archiver --force --model-name <Gx> \\ --model-file resnet.py \\ --serialized-file ./DeepLIIF_Latest_Model/latest_net_<Gx>.pth \\ --export-path model-store \\ --handler net_handler.py \\ --requirements-file model_requirements.txt and for the UNets ( G51 , G52 , G53 , G54 , G54 ) switch the model file from resnet.py to unet.py : torch-model-archiver --force --model-name <G5x> \\ --model-file unet.py \\ --serialized-file ./DeepLIIF_Latest_Model/latest_net_<G5x>.pth \\ --export-path model-store \\ --handler net_handler.py \\ --requirements-file model_requirements.txt Once all the models have been packaged and made available in the model store, they can be composed into a workflow archive. Finally, create the archive for the workflow represented in Figure 3. torch-workflow-archiver -f --workflow-name deepliif \\ --spec-file deepliif_workflow.yaml \\ --handler deepliif_workflow_handler.py \\ --export-path model-store Run the server Once all artifacts are available in the model store, run the model server. torchserve --start --ncs \\ --model-store model-store \\ --workflow-store model-store \\ --ts-config config.properties An additional step is needed to register the deepliif workflow on the server. curl -X POST \"http://127.0.0.1:8081/workflows?url=deepliif.war\" Run inference using Python The snippet below shows an example of how to cosume the Torchserve workflow API using Python. import base64 import requests from io import BytesIO import torch from deepliif.preprocessing import transform def deserialize_tensor(bs): return torch.load(BytesIO(base64.b64decode(bs.encode()))) def serialize_tensor(ts): buffer = BytesIO() torch.save(ts, buffer) return base64.b64encode(buffer.getvalue()).decode('utf-8') TORCHSERVE_HOST = 'http://127.0.0.1:8080' img = load_tile() ts = transform(img.resize((512, 512))) res = requests.post( f'{TORCHSERVE_HOST}/wfpredict/deepliif', json={'img': serialize_tensor(ts)} ) res.raise_for_status() masks = {k: deserialize_tensor(v) for k, v in res.json().items()}","title":"Deployment"},{"location":"deployment/#docker","text":"We provide a Dockerfile that can be used to run the DeepLIIF models inside a container. First, you need to install the Docker Engine . After installing the Docker, you need to follow these steps: Download the pretrained model and place them in DeepLIIF/checkpoints/DeepLIIF_Latest_Model. Change XXX of the WORKDIR line in the DockerFile to the directory containing the DeepLIIF project. To create a docker image from the docker file: docker build -t cuda/deepliif . The image is then used as a base. You can copy and use it to run an application. The application needs an isolated environment in which to run, referred to as a container. To create and run a container: docker run -it -v `pwd`:`pwd` -w `pwd` cuda/deepliif deepliif test --input-dir Sample_Large_Tissues When you run a container from the image, the deepliif CLI will be available. You can easily run any CLI command in the activated environment and copy the results from the docker container to the host.","title":"Docker"},{"location":"deployment/#dask-deployment","text":"By default, DeepLIIF networks are deployed using a combination of TorchScript and Dask. Torchscript is used to serialize and optimize the models starting from a pre-trained model checkpoint and the Python code that describes the models. For more details check out the Serialize Model section on the documentation. Models parallelization and interdependencies are expressed using Dask Delayed functions that allow us to build a computational graph with minimal code annotations. The concrete implementation can be found on the run_dask() function under the deepliif.models module.","title":"Dask deployment"},{"location":"deployment/#torchserve-deployment","text":"This section describes how to run DeepLIIF's inference using Torchserve workflows. Workflows con be composed by both PyTorch models and Python functions that can be connected through a DAG. For DeepLIIF there are 4 main stages (see Figure 3): Pre-process deserialize the image from the request and return a tensor created from it. G1-4 run the ResNets to generate the Hematoxylin, DAPI, LAP2 and Ki67 masks. G51-5 run the UNets and apply Weighted Average to generate the Segmentation image. Aggregate aggregate and serialize the results and return to user. Composition of DeepLIIF nets into a Torchserve workflow. In practice, users need to call this workflow for each tile generated from the original image. A common use case scenario would be: Load an IHC image and generate the tiles. For each tile: Resize to 512x512 and transform to tensor. Serialize the tensor and use the inference API to generate all the masks. Deserialize the results. Stitch back the results and apply post-processing operations. The next sections show how to deploy the model server.","title":"Torchserve deployment"},{"location":"deployment/#prerequisites","text":"1. Install Torchserve and torch-model-archiver following these instructions . In MacOS, navigate to the model-server directory: cd model-server python3 -m venv venv source venv/bin/activate pip install torch torchserve torch-model-archiver torch-workflow-archiver 2. Download and unzip the latest version of the DeepLIIF models from zenodo . wget https://zenodo.org/record/4751737/files/DeepLIIF_Latest_Model.zip unzip DeepLIIF_Latest_Model.zip","title":"Prerequisites"},{"location":"deployment/#package-models-and-workflow","text":"In order to run the DeepLIIF nets using Torchserve, they first need to be archived as MAR files. In this section we will create the model artifacts and archive them in the model store. First, inside model-server create a directory to store the models. mkdir model-store For every ResNet ( G1 , G2 , G3 , G4 ) run replacing the name of the net: torch-model-archiver --force --model-name <Gx> \\ --model-file resnet.py \\ --serialized-file ./DeepLIIF_Latest_Model/latest_net_<Gx>.pth \\ --export-path model-store \\ --handler net_handler.py \\ --requirements-file model_requirements.txt and for the UNets ( G51 , G52 , G53 , G54 , G54 ) switch the model file from resnet.py to unet.py : torch-model-archiver --force --model-name <G5x> \\ --model-file unet.py \\ --serialized-file ./DeepLIIF_Latest_Model/latest_net_<G5x>.pth \\ --export-path model-store \\ --handler net_handler.py \\ --requirements-file model_requirements.txt Once all the models have been packaged and made available in the model store, they can be composed into a workflow archive. Finally, create the archive for the workflow represented in Figure 3. torch-workflow-archiver -f --workflow-name deepliif \\ --spec-file deepliif_workflow.yaml \\ --handler deepliif_workflow_handler.py \\ --export-path model-store","title":"Package models and workflow"},{"location":"deployment/#run-the-server","text":"Once all artifacts are available in the model store, run the model server. torchserve --start --ncs \\ --model-store model-store \\ --workflow-store model-store \\ --ts-config config.properties An additional step is needed to register the deepliif workflow on the server. curl -X POST \"http://127.0.0.1:8081/workflows?url=deepliif.war\"","title":"Run the server"},{"location":"deployment/#run-inference-using-python","text":"The snippet below shows an example of how to cosume the Torchserve workflow API using Python. import base64 import requests from io import BytesIO import torch from deepliif.preprocessing import transform def deserialize_tensor(bs): return torch.load(BytesIO(base64.b64decode(bs.encode()))) def serialize_tensor(ts): buffer = BytesIO() torch.save(ts, buffer) return base64.b64encode(buffer.getvalue()).decode('utf-8') TORCHSERVE_HOST = 'http://127.0.0.1:8080' img = load_tile() ts = transform(img.resize((512, 512))) res = requests.post( f'{TORCHSERVE_HOST}/wfpredict/deepliif', json={'img': serialize_tensor(ts)} ) res.raise_for_status() masks = {k: deserialize_tensor(v) for k, v in res.json().items()}","title":"Run inference using Python"},{"location":"installation/","text":"Installation Prerequisites Python 3.8 Docker Installing deepliif DeepLIIF can be pip installed: $ python3.8 -m venv venv $ source venv/bin/activate (venv) $ pip install git+https://github.com/nadeemlab/DeepLIIF.git The package is composed of two parts: A library that implements the core functions used to train and test DeepLIIF models. A CLI to run common batch operations including training, batch testing and Torchscipt models serialization. You can list all available commands: (venv) $ deepliif --help Usage: deepliif [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. Commands: prepare-training-data Preparing data for training serialize Serialize DeepLIIF models using Torchscript test Test trained models train General-purpose training script for multi-task...","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#prerequisites","text":"Python 3.8 Docker","title":"Prerequisites"},{"location":"installation/#installing-deepliif","text":"DeepLIIF can be pip installed: $ python3.8 -m venv venv $ source venv/bin/activate (venv) $ pip install git+https://github.com/nadeemlab/DeepLIIF.git The package is composed of two parts: A library that implements the core functions used to train and test DeepLIIF models. A CLI to run common batch operations including training, batch testing and Torchscipt models serialization. You can list all available commands: (venv) $ deepliif --help Usage: deepliif [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. Commands: prepare-training-data Preparing data for training serialize Serialize DeepLIIF models using Torchscript test Test trained models train General-purpose training script for multi-task...","title":"Installing deepliif"},{"location":"testing/","text":"Testing Serialize Model The installed deepliif uses Dask to perform inference on the input IHC images. Before running the test command, the model files must be serialized using Torchscript. To serialize the model files: deepliif serialize --models-dir /path/to/input/model/files --output-dir /path/to/output/model/files By default, the model files are expected to be located in DeepLIIF/model-server/DeepLIIF_Latest_Model . By default, the serialized files will be saved to the same directory as the input model files. Testing To test the model: deepliif test --input-dir /path/to/input/images --output-dir /path/to/output/images --tile-size 512 The latest version of the pretrained models can be downloaded here . Before running test on images, the model files must be serialized as described above. The serialized model files are expected to be located in DeepLIIF/model-server/DeepLIIF_Latest_Model . The test results will be saved to the specified output directory, which defaults to the input directory. The default tile size is 512. Testing datasets can be downloaded here . If you prefer, it is possible to run the model using Torchserve. Please see below for instructions on how to deploy the model with Torchserve and for an example of how to run the inference.","title":"Testing"},{"location":"testing/#testing","text":"","title":"Testing"},{"location":"testing/#serialize-model","text":"The installed deepliif uses Dask to perform inference on the input IHC images. Before running the test command, the model files must be serialized using Torchscript. To serialize the model files: deepliif serialize --models-dir /path/to/input/model/files --output-dir /path/to/output/model/files By default, the model files are expected to be located in DeepLIIF/model-server/DeepLIIF_Latest_Model . By default, the serialized files will be saved to the same directory as the input model files.","title":"Serialize Model"},{"location":"testing/#testing_1","text":"To test the model: deepliif test --input-dir /path/to/input/images --output-dir /path/to/output/images --tile-size 512 The latest version of the pretrained models can be downloaded here . Before running test on images, the model files must be serialized as described above. The serialized model files are expected to be located in DeepLIIF/model-server/DeepLIIF_Latest_Model . The test results will be saved to the specified output directory, which defaults to the input directory. The default tile size is 512. Testing datasets can be downloaded here . If you prefer, it is possible to run the model using Torchserve. Please see below for instructions on how to deploy the model with Torchserve and for an example of how to run the inference.","title":"Testing"},{"location":"training/","text":"Training Training Dataset For training, all image sets must be 512x512 and combined together in 3072x512 images (six images of size 512x512 stitched together horizontally). The data need to be arranged in the following order: XXX_Dataset \u251c\u2500\u2500 train \u2514\u2500\u2500 val We have provided a simple function in the CLI for preparing data for training. To prepare data for training , you need to have the image dataset for each image (including IHC, Hematoxylin Channel, mpIF DAPI, mpIF Lap2, mpIF marker, and segmentation mask) in the input directory. Each of the six images for a single image set must have the same naming format, with only the name of the label for the type of image differing between them. The label names must be, respectively: IHC, Hematoxylin, DAPI, Lap2, Marker, Seg. The command takes the address of the directory containing image set data and the address of the output dataset directory. It first creates the train and validation directories inside the given output dataset directory. It then reads all of the images in the input directory and saves the combined image in the train or validation directory, based on the given validation_ratio . deepliif prepare-training-data --input-dir /path/to/input/images --output-dir /path/to/output/images --validation-ratio 0.2 Training To train a model: deepliif train --dataroot /path/to/input/images --name Model_Name To view training losses and results, open the URL http://localhost:8097. For cloud servers replace localhost with your IP. Epoch-wise intermediate training results are in DeepLIIF/checkpoints/Model_Name/web/index.html . Trained models will be by default be saved in DeepLIIF/checkpoints/Model_Name . Training datasets can be downloaded here . Multi-GPU Training There are 2 ways you can leverage multiple GPUs to train DeepLIIF, Data Parallel (DP) or Distributed Data Parallel (DDP) . Both cases are a kind of data parallelism supported by PyTorch. The key difference is that DP is single process multi-threading while DDP can have multiple processes . TL;DR Use DP if you - are used to the way to train DeepLIIF on multiple GPUs since its first release, OR - do not have multiple GPU machines to utilize, OR - are fine with the training being a bit slower Use DDP if you - are willing to try a slightly different way to launch the training than before, OR - do have multiple GPU machines for cross-node distribution, OR - want to get as fast training as possible Data Parallel (DP) DP is single-process. It means that all the GPUs you want to use must be on the same machine so that they can be included in the same process - you cannot distribute the training across multiple GPU machines, unless you write your own code to handle inter-node (node = machine) communication. To split and manage the workload for multiple GPUs within the same process, DP uses multi-threading. It is worth noting that multi-threading in this case can lead to significant performance overhead, and slow down your training. See a short discussion in PyTorch's CUDA Best Practices . Train with DP Example with 2 GPUs (of course on 1 machine): deepliif train --dataroot <data_dir> --batch-size 6 --gpu-ids 0 --gpu-ids 1 Note that batch-size is defined per process. Since DP is a single-process method, the batch-size you set is the effective batch size. Distributed Data Parallel (DDP) DDP usually spawns multiple processes. DeepLIIF's code follows the PyTorch recommendation to spawn 1 process per GPU ( doc ). If you want to assign multiple GPUs to each process, you will need to make modifications to DeepLIIF's code (see doc ). Despite all the benefits of DDP, one drawback is the extra GPU memory needed for dedicated CUDA buffer for communication. See a short discussion here . In the context of DeepLIIF, this means that there might be situations where you could use a bigger batch size with DP as compared to DDP, which may actually train faster than using DDP with a smaller batch size. Train with DDP 1. Local Machine To launch training using DDP on a local machine, use deepliif trainlaunch . Example with 2 GPUs (on 1 machine): deepliif trainlaunch --dataroot <data_dir> --batch-size 3 --gpu-ids 0 --gpu-ids 1 --use-torchrun \"--nproc_per_node 2\" Note that batch-size is defined per process. Since DDP is a single-process method, the batch-size you set is the batch size for each process, and the effective batch size will be batch-size multiplied by the number of processes you started. In the above example, it will be 3 * 2 = 6. You still need to provide all GPU ids to use to the training command. Internally, in each process DeepLIIF picks the device using gpu_ids[local_rank] . If you provide --gpu-ids 2 --gpu-ids 3 , the process with local rank 0 will use gpu id 2 and that with local rank 1 will use gpu id 3. -t 3 --log_dir <log_dir> is not required, but is a useful setting in torchrun that saves the log from each process to your target log directory. For example: deepliif trainlaunch --dataroot <data_dir> --batch-size 3 --gpu-ids 0 --gpu-ids 1 --use-torchrun \"-t 3 --log_dir <log_dir> --nproc_per_node 2\" If your PyTorch is older than 1.10, DeepLIIF calls torch.distributed.launch in the backend. Otherwise, DeepLIIF calls torchrun . 2. Kubernetes-Based Training Service To launch training using DDP on a kubernetes-based service where each process will have its own pod and a dedicated GPU, and there is an existing task manager/scheduler in place, you may submit a script with training command like the following: import os import torch.distributed as dist def init_process(): dist.init_process_group( backend='nccl', init_method='tcp://' + os.environ['MASTER_ADDR'] + ':' + os.environ['MASTER_PORT'], rank=int(os.environ['RANK']), world_size=int(os.environ['WORLD_SIZE'])) root_folder = <data_dir> if __name__ == '__main__': init_process() subprocess.run(f'deepliif train --dataroot {root_folder} --remote True --batch-size 3 --gpu-ids 0',shell=True) Note that Always provide --gpu-ids 0 to the training command for each process/pod if the gpu id gets re-named in each pod. If not, you will need to pass the correct gpu id in a dynamic way, possibly through an environment variable in each pod. 3. Multiple Virtual Machines To launch training across multiple VMs, you can refer to the scheduler framework you use. For each process, similar to the example for kubernetes, you will need to initiate the process group so that the current process knows who it is, where are its peers, etc., and then execute the regular training command in a subprocess. Move from Single-GPU to Multi-GPU: Impact on Hyper-Parameters To achieve equivalently good training results, you may want to adjust some hyper-parameters you figured out for a single GPU training. Batch Size & Learning Rate Backward propagation by default runs at the end of every batch to find how much change to make in parameters. An immediate outcome from using multiple GPUs is that we have a larger effective batch size. In DDP, this means fewer gradient descent because DDP averages the gradients from all processes ( doc ). Assume that in 1 epoch, a single-GPU training does gradient descent for 200 times. Now with 2 GPUs/processes, the training will have 100 batches in each process and does the gradient descent using the averaged gradients of the 2 GPUs/processes, one for each batch, which is 100 times. You may want to compensate this by increasing the learning rate proportionally. DP is slightly different, in that it sums up the gradients from all GPUs/threads ( doc ). However, practically the performance (accuracy) still suffers from the larger effective batch size, which can be mitigated by increasing the learning rate. Track Training Progress in Visualizer When using multiple GPUs for training, tracking training progress in the visdom visualizer can be tricky. It may not be a big issue for DP which uses only 1 process, but definitely the multi-processing in DDP brings a challenge. With DDP, each process trains on its own slice of data that is different from the others. If we plot the training progress from the processes in terms of losses, the raw values will not be comparable, and you will see a different graph from each process. These graphs might be close, but will not be exactly the same. Currently, if you use multiple processes (DDP), you are suggested to: pass --remote True to the training command, even if you are running on a local machine open a terminal in an environment you intend to have visdom running (it can be the same place where you train the model, or a separate machine), and run deepliif visualize : deepliif visualize --pickle_dir <pickle_dir> By default, the pickle files are stored under <checkpoint_dir_in_training_command>/<name_in_training_command>/pickle . --remote True in the training command triggers DeepLIIF to i) not start a visdom session and ii) persist the input into the visdom graphs as pickle files. If there are multiple processes, it will only persist the information such as losses from the first process (process with rank 0) . The visualize command deepliif visualize then starts the visdom, scans the pickle directory you provided periodically, and updates the graphs if there is an update in any pickled snapshot. If you plan to train the model in a different place from where you would like to host visdom (e.g., situation 2 & 3 in DDP mentioned above), you need to make sure that this pickle directory is accessible by both the training environment and the visdom environment . For example: use a storage volume mounted to both environments, so you can access this storage simply using a file path use an external storage of your choice For training 1. write a script that contains one function DeepLIIF can call to transfer the files like the following: import boto3 credentials = <s3 credentials> # make sure that the first argument is the source path def save_to_s3(source_path): # make sure the file name part is still unchanged, e.g., by keeping source_path.split('/')[-1] target_path = ... s3 = boto3.client('s3') with open(source_path, \"rb\") as f: s3.upload_fileobj(f, credentials[\"bucket_name\"], target_path) 2. save it in a directory where you will call the training command; let's say the script is called mysave.py 3. tell DeepLIIF to use this by passing --remote-transfer-cmd mysave.save_to_s3 to the training command (take kubernetes-based training service as an example): import os import torch.distributed as dist def init_process(): dist.init_process_group( backend='nccl', init_method='tcp://' + os.environ['MASTER_ADDR'] + ':' + os.environ['MASTER_PORT'], rank=int(os.environ['RANK']), world_size=int(os.environ['WORLD_SIZE'])) root_folder = <data_dir> if __name__ == '__main__': init_process() subprocess.run(f'deepliif train --dataroot {root_folder} --remote True --batch-size 3 --gpu-ids 0 --remote True, --remote-transfer-cmd mysave.save_to_s3',shell=True) note that this method if used will be applied not only on the pickled snapshots for visdom input, but also the model files DeepLIIF saves : DeepLIIF will trigger this provided method to store an additional copy of the model files into your external storage For visualization periodically check and download the latest pickle files from your external storage to your local environment pass the pickle directory in your local enviroment to deepliif visualize Synthetic Data Generation The first version of DeepLIIF model suffered from its inability to separate IHC positive cells in some large clusters, resulting from the absence of clustered positive cells in our training data. To infuse more information about the clustered positive cells into our model, we present a novel approach for the synthetic generation of IHC images using co-registered data. We design a GAN-based model that receives the Hematoxylin channel, the mpIF DAPI image, and the segmentation mask and generates the corresponding IHC image. The model converts the Hematoxylin channel to gray-scale to infer more helpful information such as the texture and discard unnecessary information such as color. The Hematoxylin image guides the network to synthesize the background of the IHC image by preserving the shape and texture of the cells and artifacts in the background. The DAPI image assists the network in identifying the location, shape, and texture of the cells to better isolate the cells from the background. The segmentation mask helps the network specify the color of cells based on the type of the cell (positive cell: a brown hue, negative: a blue hue). In the next step, we generate synthetic IHC images with more clustered positive cells. To do so, we change the segmentation mask by choosing a percentage of random negative cells in the segmentation mask (called as Neg-to-Pos) and converting them into positive cells. Some samples of the synthesized IHC images along with the original IHC image are shown below. Overview of synthetic IHC image generation. (a) A training sample of the IHC-generator model. (b) Some samples of synthesized IHC images using the trained IHC-Generator model. The Neg-to-Pos shows the percentage of the negative cells in the segmentation mask converted to positive cells. We created a new dataset using the original IHC images and synthetic IHC images. We synthesize each image in the dataset two times by setting the Neg-to-Pos parameter to %50 and %70. We re-trained our network with the new dataset. You can find the new trained model here . Registration To register the de novo stained mpIF and IHC images, you can use the registration framework in the 'Registration' directory. Please refer to the README file provided in the same directory for more details. Contributing Training Data To train DeepLIIF, we used a dataset of lung and bladder tissues containing IHC, hematoxylin, mpIF DAPI, mpIF Lap2, and mpIF Ki67 of the same tissue scanned using ZEISS Axioscan. These images were scaled and co-registered with the fixed IHC images using affine transformations, resulting in 1667 co-registered sets of IHC and corresponding multiplex images of size 512x512. We randomly selected 709 sets for training, 358 sets for validation, and 600 sets for testing the model. We also randomly selected and segmented 41 images of size 640x640 from recently released BCDataset which contains Ki67 stained sections of breast carcinoma with Ki67+ and Ki67- cell centroid annotations (for cell detection rather than cell instance segmentation task). We split these tiles into 164 images of size 512x512; the test set varies widely in the density of tumor cells and the Ki67 index. You can find this dataset here . We are also creating a self-configurable version of DeepLIIF which will take as input any co-registered H&E/IHC and multiplex images and produce the optimal output. If you are generating or have generated H&E/IHC and multiplex staining for the same slide (de novo staining) and would like to contribute that data for DeepLIIF, we can perform co-registration, whole-cell multiplex segmentation via ImPartial , train the DeepLIIF model and release back to the community with full credit to the contributors.","title":"Training"},{"location":"training/#training","text":"","title":"Training"},{"location":"training/#training-dataset","text":"For training, all image sets must be 512x512 and combined together in 3072x512 images (six images of size 512x512 stitched together horizontally). The data need to be arranged in the following order: XXX_Dataset \u251c\u2500\u2500 train \u2514\u2500\u2500 val We have provided a simple function in the CLI for preparing data for training. To prepare data for training , you need to have the image dataset for each image (including IHC, Hematoxylin Channel, mpIF DAPI, mpIF Lap2, mpIF marker, and segmentation mask) in the input directory. Each of the six images for a single image set must have the same naming format, with only the name of the label for the type of image differing between them. The label names must be, respectively: IHC, Hematoxylin, DAPI, Lap2, Marker, Seg. The command takes the address of the directory containing image set data and the address of the output dataset directory. It first creates the train and validation directories inside the given output dataset directory. It then reads all of the images in the input directory and saves the combined image in the train or validation directory, based on the given validation_ratio . deepliif prepare-training-data --input-dir /path/to/input/images --output-dir /path/to/output/images --validation-ratio 0.2","title":"Training Dataset"},{"location":"training/#training_1","text":"To train a model: deepliif train --dataroot /path/to/input/images --name Model_Name To view training losses and results, open the URL http://localhost:8097. For cloud servers replace localhost with your IP. Epoch-wise intermediate training results are in DeepLIIF/checkpoints/Model_Name/web/index.html . Trained models will be by default be saved in DeepLIIF/checkpoints/Model_Name . Training datasets can be downloaded here .","title":"Training"},{"location":"training/#multi-gpu-training","text":"There are 2 ways you can leverage multiple GPUs to train DeepLIIF, Data Parallel (DP) or Distributed Data Parallel (DDP) . Both cases are a kind of data parallelism supported by PyTorch. The key difference is that DP is single process multi-threading while DDP can have multiple processes . TL;DR Use DP if you - are used to the way to train DeepLIIF on multiple GPUs since its first release, OR - do not have multiple GPU machines to utilize, OR - are fine with the training being a bit slower Use DDP if you - are willing to try a slightly different way to launch the training than before, OR - do have multiple GPU machines for cross-node distribution, OR - want to get as fast training as possible","title":"Multi-GPU Training"},{"location":"training/#data-parallel-dp","text":"DP is single-process. It means that all the GPUs you want to use must be on the same machine so that they can be included in the same process - you cannot distribute the training across multiple GPU machines, unless you write your own code to handle inter-node (node = machine) communication. To split and manage the workload for multiple GPUs within the same process, DP uses multi-threading. It is worth noting that multi-threading in this case can lead to significant performance overhead, and slow down your training. See a short discussion in PyTorch's CUDA Best Practices .","title":"Data Parallel (DP)"},{"location":"training/#train-with-dp","text":"Example with 2 GPUs (of course on 1 machine): deepliif train --dataroot <data_dir> --batch-size 6 --gpu-ids 0 --gpu-ids 1 Note that batch-size is defined per process. Since DP is a single-process method, the batch-size you set is the effective batch size.","title":"Train with DP"},{"location":"training/#distributed-data-parallel-ddp","text":"DDP usually spawns multiple processes. DeepLIIF's code follows the PyTorch recommendation to spawn 1 process per GPU ( doc ). If you want to assign multiple GPUs to each process, you will need to make modifications to DeepLIIF's code (see doc ). Despite all the benefits of DDP, one drawback is the extra GPU memory needed for dedicated CUDA buffer for communication. See a short discussion here . In the context of DeepLIIF, this means that there might be situations where you could use a bigger batch size with DP as compared to DDP, which may actually train faster than using DDP with a smaller batch size.","title":"Distributed Data Parallel (DDP)"},{"location":"training/#train-with-ddp","text":"","title":"Train with DDP"},{"location":"training/#1-local-machine","text":"To launch training using DDP on a local machine, use deepliif trainlaunch . Example with 2 GPUs (on 1 machine): deepliif trainlaunch --dataroot <data_dir> --batch-size 3 --gpu-ids 0 --gpu-ids 1 --use-torchrun \"--nproc_per_node 2\" Note that batch-size is defined per process. Since DDP is a single-process method, the batch-size you set is the batch size for each process, and the effective batch size will be batch-size multiplied by the number of processes you started. In the above example, it will be 3 * 2 = 6. You still need to provide all GPU ids to use to the training command. Internally, in each process DeepLIIF picks the device using gpu_ids[local_rank] . If you provide --gpu-ids 2 --gpu-ids 3 , the process with local rank 0 will use gpu id 2 and that with local rank 1 will use gpu id 3. -t 3 --log_dir <log_dir> is not required, but is a useful setting in torchrun that saves the log from each process to your target log directory. For example: deepliif trainlaunch --dataroot <data_dir> --batch-size 3 --gpu-ids 0 --gpu-ids 1 --use-torchrun \"-t 3 --log_dir <log_dir> --nproc_per_node 2\" If your PyTorch is older than 1.10, DeepLIIF calls torch.distributed.launch in the backend. Otherwise, DeepLIIF calls torchrun .","title":"1. Local Machine"},{"location":"training/#2-kubernetes-based-training-service","text":"To launch training using DDP on a kubernetes-based service where each process will have its own pod and a dedicated GPU, and there is an existing task manager/scheduler in place, you may submit a script with training command like the following: import os import torch.distributed as dist def init_process(): dist.init_process_group( backend='nccl', init_method='tcp://' + os.environ['MASTER_ADDR'] + ':' + os.environ['MASTER_PORT'], rank=int(os.environ['RANK']), world_size=int(os.environ['WORLD_SIZE'])) root_folder = <data_dir> if __name__ == '__main__': init_process() subprocess.run(f'deepliif train --dataroot {root_folder} --remote True --batch-size 3 --gpu-ids 0',shell=True) Note that Always provide --gpu-ids 0 to the training command for each process/pod if the gpu id gets re-named in each pod. If not, you will need to pass the correct gpu id in a dynamic way, possibly through an environment variable in each pod.","title":"2. Kubernetes-Based Training Service"},{"location":"training/#3-multiple-virtual-machines","text":"To launch training across multiple VMs, you can refer to the scheduler framework you use. For each process, similar to the example for kubernetes, you will need to initiate the process group so that the current process knows who it is, where are its peers, etc., and then execute the regular training command in a subprocess.","title":"3. Multiple Virtual Machines"},{"location":"training/#move-from-single-gpu-to-multi-gpu-impact-on-hyper-parameters","text":"To achieve equivalently good training results, you may want to adjust some hyper-parameters you figured out for a single GPU training.","title":"Move from Single-GPU to Multi-GPU: Impact on Hyper-Parameters"},{"location":"training/#batch-size-learning-rate","text":"Backward propagation by default runs at the end of every batch to find how much change to make in parameters. An immediate outcome from using multiple GPUs is that we have a larger effective batch size. In DDP, this means fewer gradient descent because DDP averages the gradients from all processes ( doc ). Assume that in 1 epoch, a single-GPU training does gradient descent for 200 times. Now with 2 GPUs/processes, the training will have 100 batches in each process and does the gradient descent using the averaged gradients of the 2 GPUs/processes, one for each batch, which is 100 times. You may want to compensate this by increasing the learning rate proportionally. DP is slightly different, in that it sums up the gradients from all GPUs/threads ( doc ). However, practically the performance (accuracy) still suffers from the larger effective batch size, which can be mitigated by increasing the learning rate.","title":"Batch Size &amp; Learning Rate"},{"location":"training/#track-training-progress-in-visualizer","text":"When using multiple GPUs for training, tracking training progress in the visdom visualizer can be tricky. It may not be a big issue for DP which uses only 1 process, but definitely the multi-processing in DDP brings a challenge. With DDP, each process trains on its own slice of data that is different from the others. If we plot the training progress from the processes in terms of losses, the raw values will not be comparable, and you will see a different graph from each process. These graphs might be close, but will not be exactly the same. Currently, if you use multiple processes (DDP), you are suggested to: pass --remote True to the training command, even if you are running on a local machine open a terminal in an environment you intend to have visdom running (it can be the same place where you train the model, or a separate machine), and run deepliif visualize : deepliif visualize --pickle_dir <pickle_dir> By default, the pickle files are stored under <checkpoint_dir_in_training_command>/<name_in_training_command>/pickle . --remote True in the training command triggers DeepLIIF to i) not start a visdom session and ii) persist the input into the visdom graphs as pickle files. If there are multiple processes, it will only persist the information such as losses from the first process (process with rank 0) . The visualize command deepliif visualize then starts the visdom, scans the pickle directory you provided periodically, and updates the graphs if there is an update in any pickled snapshot. If you plan to train the model in a different place from where you would like to host visdom (e.g., situation 2 & 3 in DDP mentioned above), you need to make sure that this pickle directory is accessible by both the training environment and the visdom environment . For example: use a storage volume mounted to both environments, so you can access this storage simply using a file path use an external storage of your choice For training 1. write a script that contains one function DeepLIIF can call to transfer the files like the following: import boto3 credentials = <s3 credentials> # make sure that the first argument is the source path def save_to_s3(source_path): # make sure the file name part is still unchanged, e.g., by keeping source_path.split('/')[-1] target_path = ... s3 = boto3.client('s3') with open(source_path, \"rb\") as f: s3.upload_fileobj(f, credentials[\"bucket_name\"], target_path) 2. save it in a directory where you will call the training command; let's say the script is called mysave.py 3. tell DeepLIIF to use this by passing --remote-transfer-cmd mysave.save_to_s3 to the training command (take kubernetes-based training service as an example): import os import torch.distributed as dist def init_process(): dist.init_process_group( backend='nccl', init_method='tcp://' + os.environ['MASTER_ADDR'] + ':' + os.environ['MASTER_PORT'], rank=int(os.environ['RANK']), world_size=int(os.environ['WORLD_SIZE'])) root_folder = <data_dir> if __name__ == '__main__': init_process() subprocess.run(f'deepliif train --dataroot {root_folder} --remote True --batch-size 3 --gpu-ids 0 --remote True, --remote-transfer-cmd mysave.save_to_s3',shell=True) note that this method if used will be applied not only on the pickled snapshots for visdom input, but also the model files DeepLIIF saves : DeepLIIF will trigger this provided method to store an additional copy of the model files into your external storage For visualization periodically check and download the latest pickle files from your external storage to your local environment pass the pickle directory in your local enviroment to deepliif visualize","title":"Track Training Progress in Visualizer"},{"location":"training/#synthetic-data-generation","text":"The first version of DeepLIIF model suffered from its inability to separate IHC positive cells in some large clusters, resulting from the absence of clustered positive cells in our training data. To infuse more information about the clustered positive cells into our model, we present a novel approach for the synthetic generation of IHC images using co-registered data. We design a GAN-based model that receives the Hematoxylin channel, the mpIF DAPI image, and the segmentation mask and generates the corresponding IHC image. The model converts the Hematoxylin channel to gray-scale to infer more helpful information such as the texture and discard unnecessary information such as color. The Hematoxylin image guides the network to synthesize the background of the IHC image by preserving the shape and texture of the cells and artifacts in the background. The DAPI image assists the network in identifying the location, shape, and texture of the cells to better isolate the cells from the background. The segmentation mask helps the network specify the color of cells based on the type of the cell (positive cell: a brown hue, negative: a blue hue). In the next step, we generate synthetic IHC images with more clustered positive cells. To do so, we change the segmentation mask by choosing a percentage of random negative cells in the segmentation mask (called as Neg-to-Pos) and converting them into positive cells. Some samples of the synthesized IHC images along with the original IHC image are shown below. Overview of synthetic IHC image generation. (a) A training sample of the IHC-generator model. (b) Some samples of synthesized IHC images using the trained IHC-Generator model. The Neg-to-Pos shows the percentage of the negative cells in the segmentation mask converted to positive cells. We created a new dataset using the original IHC images and synthetic IHC images. We synthesize each image in the dataset two times by setting the Neg-to-Pos parameter to %50 and %70. We re-trained our network with the new dataset. You can find the new trained model here .","title":"Synthetic Data Generation"},{"location":"training/#registration","text":"To register the de novo stained mpIF and IHC images, you can use the registration framework in the 'Registration' directory. Please refer to the README file provided in the same directory for more details.","title":"Registration"},{"location":"training/#contributing-training-data","text":"To train DeepLIIF, we used a dataset of lung and bladder tissues containing IHC, hematoxylin, mpIF DAPI, mpIF Lap2, and mpIF Ki67 of the same tissue scanned using ZEISS Axioscan. These images were scaled and co-registered with the fixed IHC images using affine transformations, resulting in 1667 co-registered sets of IHC and corresponding multiplex images of size 512x512. We randomly selected 709 sets for training, 358 sets for validation, and 600 sets for testing the model. We also randomly selected and segmented 41 images of size 640x640 from recently released BCDataset which contains Ki67 stained sections of breast carcinoma with Ki67+ and Ki67- cell centroid annotations (for cell detection rather than cell instance segmentation task). We split these tiles into 164 images of size 512x512; the test set varies widely in the density of tumor cells and the Ki67 index. You can find this dataset here . We are also creating a self-configurable version of DeepLIIF which will take as input any co-registered H&E/IHC and multiplex images and produce the optimal output. If you are generating or have generated H&E/IHC and multiplex staining for the same slide (de novo staining) and would like to contribute that data for DeepLIIF, we can perform co-registration, whole-cell multiplex segmentation via ImPartial , train the DeepLIIF model and release back to the community with full credit to the contributors.","title":"Contributing Training Data"}]}