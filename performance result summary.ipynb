{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesser-chamber",
   "metadata": {
    "id": "71c188b2-0d1e-42fa-970e-25212064b1b7"
   },
   "source": [
    "# Performance Result Summary\n",
    "Generate training time statistics from log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bronze-royal",
   "metadata": {
    "id": "04a9ce7c-90c8-4e60-b702-dde81aa9f37a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-suicide",
   "metadata": {
    "id": "8a8dfc2a-0f10-4118-9409-1f50404c8c7f"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-syracuse",
   "metadata": {
    "id": "3a324e22-4091-4484-b96a-6b8f6a6d097e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_number_seq(l):\n",
    "    \"\"\"\n",
    "    This functions find the sequence of consecutive numbers.\n",
    "    Example: \n",
    "      input: [1,2,3,5,6]\n",
    "      output: 1-3, 5-6\n",
    "    \n",
    "    l: a sequence of numbers, in numeric data type\n",
    "    \"\"\"\n",
    "    l_res = []\n",
    "    \n",
    "    for i,v in enumerate(l):\n",
    "        if i == 0:\n",
    "            int_s = v\n",
    "            int_e = None\n",
    "        else:\n",
    "            if v-l[i-1] == 1:\n",
    "                pass\n",
    "            else:\n",
    "                int_e = l[i-1]\n",
    "                l_res.append(f'{int_s}-{int_e}')\n",
    "                int_s = v\n",
    "                int_e = None\n",
    "    if int_e is None:\n",
    "        int_e = v\n",
    "        l_res.append(f'{int_s}-{int_e}')\n",
    "    return ', '.join(l_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proper-nitrogen",
   "metadata": {
    "id": "4fe27818-9761-4dce-8d02-5617924cb7fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_statistics(fn_or_dir,dir_log,type_log='f'):\n",
    "    \"\"\"\n",
    "    fn_or_dir: file name for a log file, or directory name for a directory of logs from torchrun\n",
    "    dir_log: a directory of all log files/dirs to search\n",
    "    type_log: f / file or d / dir / directory\n",
    "              f / file: one-file log\n",
    "              d / dir / directory: directory of logs created by torchrun\n",
    "    \"\"\"\n",
    "    if type_log in ['f','file']:\n",
    "        with open(dir_log+'/'+fn_or_dir,'r') as f:\n",
    "            text = f.readlines()\n",
    "    \n",
    "        tokens = fn_or_dir.replace('.log','').split()\n",
    "    \n",
    "    elif type_log in ['d', 'dir', 'directory']:\n",
    "        text = []\n",
    "        count = 0\n",
    "        for attempt in os.listdir(dir_log+'/'+fn_or_dir):\n",
    "            for worker in os.listdir(dir_log+'/'+fn_or_dir+'/'+attempt):\n",
    "                with open(dir_log+'/'+fn_or_dir+'/'+attempt+'/'+worker+'/stdout.log','r') as f:\n",
    "                    text = text + f.readlines()\n",
    "                    count += 1\n",
    "        print(f'[{type_log}] loaded {count} log files')\n",
    "        \n",
    "        tokens = fn_or_dir.split(';')[0].split()\n",
    "    else:\n",
    "        raise Exception(f'type_log should be either f / file, or d / dir / directory, not {type_log}')\n",
    "        \n",
    "    try:\n",
    "        fn_type = tokens[1]\n",
    "    except:\n",
    "        fn_type = 'train'#tokens[0]\n",
    "    \n",
    "    messed_lines = [line for line in text if line.startswith('\\x00')]\n",
    "    if (len(messed_lines)>0):\n",
    "        print(f'[{type_log}] {fn_or_dir} has {len(messed_lines)} lines messed up')\n",
    "        \n",
    "    if fn_type == 'train':\n",
    "        print(f'[{type_log}] {fn_or_dir}')\n",
    "        key_lines = [line for line in text if line.startswith('End')]\n",
    "        \n",
    "\n",
    "        pattern = '(\\d+) sec'\n",
    "        l_res_time = []\n",
    "        for line in key_lines:\n",
    "            l_res_time.append(int(re.findall(pattern, line)[0]))\n",
    "            \n",
    "        pattern = 'End of epoch (\\d+)'\n",
    "        l_res_epoch = []\n",
    "        for line in key_lines:\n",
    "            l_res_epoch.append(int(re.findall(pattern, line)[0]))\n",
    "        epoch_ids_included = format_number_seq(l_res_epoch)\n",
    "\n",
    "        dict_res = {'count':len(l_res_time),\n",
    "                    'epochs': epoch_ids_included,\n",
    "                    'mean': np.mean(l_res_time),\n",
    "                    'std': np.std(l_res_time),\n",
    "                    'min': np.min(l_res_time),\n",
    "                    'max': np.max(l_res_time)}\n",
    "        dict_res['projected_time_s'] = dict_res['mean'] * 200\n",
    "        dict_res['projected_time_h'] = dict_res['projected_time_s'] / 60 / 60\n",
    "        dict_res['params'] = tokens[3] if len(tokens) > 3 and tokens[3] not in ['slow','fast'] else ''\n",
    "        dict_res['node'] = tokens[-1] if tokens[-1] in ['slow','fast'] else 'unknown'\n",
    "#         dict_res['text'] = key_lines\n",
    "        return dict_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-jacksonville",
   "metadata": {
    "id": "2b7edee5-d532-4304-9c70-126049bf947a"
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tough-blogger",
   "metadata": {
    "id": "f27b5bbe-a168-47b4-a836-79d510f0ba0f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wmla train 20210102 num_threads0,batch_size2,num_workers1 slow.log',\n",
       " 'ws gpu 20211121 num_threads0 fast.log',\n",
       " 'train-oldgit.log',\n",
       " 'ws train 20211123 gpu2 slow.log',\n",
       " 'wmla train 20210104 num_threads0,batch_size2,num_workers3.log',\n",
       " 'wmla train 20210101 num_threads0,batch_size2,num_workers2 slow.log',\n",
       " 'geckodriver.log',\n",
       " 'gpu.log',\n",
       " 'ws train 20211124 gpu2,batch_size4 slow.log',\n",
       " 'wmla train 20210102 num_threads0,batch_size2,num_workers3.log',\n",
       " 'ws train 20211123 batch_size2 slow.log',\n",
       " 'ws train 20211121 num_threads0 fast.log',\n",
       " 'wmla train 20210103 num_threads0,batch_size2,num_workers3.log',\n",
       " 'ws train 20211201 num_threads0 fast.log',\n",
       " 'ws train 20211124 ??? fast.log',\n",
       " 'train.log',\n",
       " 'ws gpu 20211123 batch_size2.log']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ws train 20220102 num_threads0,batch_size2,num_workers1 slow;_5a_xge_8',\n",
       " 'ws train 20220101 num_threads0,batch_size2,num_workers2 fast;__6vd5hvg']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_log = '/userfs/log'\n",
    "\n",
    "fns = [fn for fn in listdir(dir_log) if isfile(join(dir_log, fn))]\n",
    "fns = [fn for fn in fns if fn.endswith('.log') and fn.startswith('')]\n",
    "\n",
    "dirs = [d for d in listdir(dir_log) if not isfile(join(dir_log,d))]\n",
    "dirs = [d for d in dirs if len(d.split(';'))==2]\n",
    "\n",
    "display(fns)\n",
    "display(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "primary-farming",
   "metadata": {
    "id": "cecabc2b-c7fc-4655-b847-df5f4192380e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[f] wmla train 20210102 num_threads0,batch_size2,num_workers1 slow.log\n",
      "[f] ws train 20211123 gpu2 slow.log\n",
      "[f] wmla train 20210104 num_threads0,batch_size2,num_workers3.log\n",
      "[f] wmla train 20210101 num_threads0,batch_size2,num_workers2 slow.log\n",
      "[f] ws train 20211124 gpu2,batch_size4 slow.log\n",
      "[f] wmla train 20210102 num_threads0,batch_size2,num_workers3.log\n",
      "[f] ws train 20211123 batch_size2 slow.log\n",
      "[f] ws train 20211121 num_threads0 fast.log has 1 lines messed up\n",
      "[f] ws train 20211121 num_threads0 fast.log\n",
      "[f] wmla train 20210103 num_threads0,batch_size2,num_workers3.log\n",
      "[f] ws train 20211201 num_threads0 fast.log\n",
      "[f] ws train 20211124 ??? fast.log\n",
      "[d] loaded 1 log files\n",
      "[d] ws train 20220102 num_threads0,batch_size2,num_workers1 slow;_5a_xge_8\n",
      "[d] loaded 2 log files\n",
      "[d] ws train 20220101 num_threads0,batch_size2,num_workers2 fast;__6vd5hvg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>epochs</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>projected_time_s</th>\n",
       "      <th>projected_time_h</th>\n",
       "      <th>params</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmla train 20210102 num_threads0,batch_size2,num_workers1 slow.log</th>\n",
       "      <td>74</td>\n",
       "      <td>0-73</td>\n",
       "      <td>517.649</td>\n",
       "      <td>4.23445</td>\n",
       "      <td>512</td>\n",
       "      <td>545</td>\n",
       "      <td>103530</td>\n",
       "      <td>28.7583</td>\n",
       "      <td>num_threads0,batch_size2,num_workers1</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211123 gpu2 slow.log</th>\n",
       "      <td>69</td>\n",
       "      <td>0-68</td>\n",
       "      <td>519.87</td>\n",
       "      <td>3.2656</td>\n",
       "      <td>515</td>\n",
       "      <td>533</td>\n",
       "      <td>103974</td>\n",
       "      <td>28.8816</td>\n",
       "      <td>gpu2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210104 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>21</td>\n",
       "      <td>0-6, 0-6, 0-6</td>\n",
       "      <td>292.381</td>\n",
       "      <td>143.621</td>\n",
       "      <td>207</td>\n",
       "      <td>646</td>\n",
       "      <td>58476.2</td>\n",
       "      <td>16.2434</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210101 num_threads0,batch_size2,num_workers2 slow.log</th>\n",
       "      <td>402</td>\n",
       "      <td>0-200, 0-200</td>\n",
       "      <td>259.107</td>\n",
       "      <td>3.85767</td>\n",
       "      <td>253</td>\n",
       "      <td>298</td>\n",
       "      <td>51821.4</td>\n",
       "      <td>14.3948</td>\n",
       "      <td>num_threads0,batch_size2,num_workers2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211124 gpu2,batch_size4 slow.log</th>\n",
       "      <td>201</td>\n",
       "      <td>0-200</td>\n",
       "      <td>416.1</td>\n",
       "      <td>4.93742</td>\n",
       "      <td>409</td>\n",
       "      <td>453</td>\n",
       "      <td>83219.9</td>\n",
       "      <td>23.1166</td>\n",
       "      <td>gpu2,batch_size4</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210102 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>603</td>\n",
       "      <td>0-200, 0-200, 0-200</td>\n",
       "      <td>176.755</td>\n",
       "      <td>20.863</td>\n",
       "      <td>169</td>\n",
       "      <td>471</td>\n",
       "      <td>35350.9</td>\n",
       "      <td>9.8197</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211123 batch_size2 slow.log</th>\n",
       "      <td>113</td>\n",
       "      <td>0-112</td>\n",
       "      <td>526.292</td>\n",
       "      <td>3.56403</td>\n",
       "      <td>521</td>\n",
       "      <td>539</td>\n",
       "      <td>105258</td>\n",
       "      <td>29.2384</td>\n",
       "      <td>batch_size2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211121 num_threads0 fast.log</th>\n",
       "      <td>44</td>\n",
       "      <td>157-200</td>\n",
       "      <td>602.432</td>\n",
       "      <td>4.1253</td>\n",
       "      <td>597</td>\n",
       "      <td>613</td>\n",
       "      <td>120486</td>\n",
       "      <td>33.4684</td>\n",
       "      <td>num_threads0</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210103 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>97</td>\n",
       "      <td>0-31, 0-31, 0-32</td>\n",
       "      <td>183.175</td>\n",
       "      <td>50.757</td>\n",
       "      <td>169</td>\n",
       "      <td>470</td>\n",
       "      <td>36635.1</td>\n",
       "      <td>10.1764</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211201 num_threads0 fast.log</th>\n",
       "      <td>126</td>\n",
       "      <td>0-125</td>\n",
       "      <td>600.833</td>\n",
       "      <td>4.23281</td>\n",
       "      <td>595</td>\n",
       "      <td>619</td>\n",
       "      <td>120167</td>\n",
       "      <td>33.3796</td>\n",
       "      <td>num_threads0</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211124 ??? fast.log</th>\n",
       "      <td>201</td>\n",
       "      <td>0-200</td>\n",
       "      <td>576.299</td>\n",
       "      <td>4.75368</td>\n",
       "      <td>570</td>\n",
       "      <td>616</td>\n",
       "      <td>115260</td>\n",
       "      <td>32.0166</td>\n",
       "      <td>???</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20220102 num_threads0,batch_size2,num_workers1 slow;_5a_xge_8</th>\n",
       "      <td>48</td>\n",
       "      <td>0-47</td>\n",
       "      <td>506.604</td>\n",
       "      <td>4.54945</td>\n",
       "      <td>502</td>\n",
       "      <td>532</td>\n",
       "      <td>101321</td>\n",
       "      <td>28.1447</td>\n",
       "      <td>num_threads0,batch_size2,num_workers1</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20220101 num_threads0,batch_size2,num_workers2 fast;__6vd5hvg</th>\n",
       "      <td>402</td>\n",
       "      <td>0-200, 0-200</td>\n",
       "      <td>259.933</td>\n",
       "      <td>3.68984</td>\n",
       "      <td>251</td>\n",
       "      <td>284</td>\n",
       "      <td>51986.6</td>\n",
       "      <td>14.4407</td>\n",
       "      <td>num_threads0,batch_size2,num_workers2</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count               epochs  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...    74                 0-73   \n",
       "ws train 20211123 gpu2 slow.log                       69                 0-68   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...    21        0-6, 0-6, 0-6   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...   402         0-200, 0-200   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log          201                0-200   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...   603  0-200, 0-200, 0-200   \n",
       "ws train 20211123 batch_size2 slow.log               113                0-112   \n",
       "ws train 20211121 num_threads0 fast.log               44              157-200   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...    97     0-31, 0-31, 0-32   \n",
       "ws train 20211201 num_threads0 fast.log              126                0-125   \n",
       "ws train 20211124 ??? fast.log                       201                0-200   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...    48                 0-47   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...   402         0-200, 0-200   \n",
       "\n",
       "                                                       mean      std  min  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  517.649  4.23445  512   \n",
       "ws train 20211123 gpu2 slow.log                      519.87   3.2656  515   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  292.381  143.621  207   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  259.107  3.85767  253   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log           416.1  4.93742  409   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  176.755   20.863  169   \n",
       "ws train 20211123 batch_size2 slow.log              526.292  3.56403  521   \n",
       "ws train 20211121 num_threads0 fast.log             602.432   4.1253  597   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  183.175   50.757  169   \n",
       "ws train 20211201 num_threads0 fast.log             600.833  4.23281  595   \n",
       "ws train 20211124 ??? fast.log                      576.299  4.75368  570   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  506.604  4.54945  502   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  259.933  3.68984  251   \n",
       "\n",
       "                                                    max projected_time_s  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  545           103530   \n",
       "ws train 20211123 gpu2 slow.log                     533           103974   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  646          58476.2   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  298          51821.4   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log         453          83219.9   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  471          35350.9   \n",
       "ws train 20211123 batch_size2 slow.log              539           105258   \n",
       "ws train 20211121 num_threads0 fast.log             613           120486   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  470          36635.1   \n",
       "ws train 20211201 num_threads0 fast.log             619           120167   \n",
       "ws train 20211124 ??? fast.log                      616           115260   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  532           101321   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  284          51986.6   \n",
       "\n",
       "                                                   projected_time_h  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...          28.7583   \n",
       "ws train 20211123 gpu2 slow.log                             28.8816   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...          16.2434   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...          14.3948   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log                 23.1166   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...           9.8197   \n",
       "ws train 20211123 batch_size2 slow.log                      29.2384   \n",
       "ws train 20211121 num_threads0 fast.log                     33.4684   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...          10.1764   \n",
       "ws train 20211201 num_threads0 fast.log                     33.3796   \n",
       "ws train 20211124 ??? fast.log                              32.0166   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...          28.1447   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...          14.4407   \n",
       "\n",
       "                                                                                   params  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers1   \n",
       "ws train 20211123 gpu2 slow.log                                                      gpu2   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers2   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log                              gpu2,batch_size4   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "ws train 20211123 batch_size2 slow.log                                        batch_size2   \n",
       "ws train 20211121 num_threads0 fast.log                                      num_threads0   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "ws train 20211201 num_threads0 fast.log                                      num_threads0   \n",
       "ws train 20211124 ??? fast.log                                                        ???   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  num_threads0,batch_size2,num_workers1   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  num_threads0,batch_size2,num_workers2   \n",
       "\n",
       "                                                       node  \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...     slow  \n",
       "ws train 20211123 gpu2 slow.log                        slow  \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  unknown  \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...     slow  \n",
       "ws train 20211124 gpu2,batch_size4 slow.log            slow  \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  unknown  \n",
       "ws train 20211123 batch_size2 slow.log                 slow  \n",
       "ws train 20211121 num_threads0 fast.log                fast  \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  unknown  \n",
       "ws train 20211201 num_threads0 fast.log                fast  \n",
       "ws train 20211124 ??? fast.log                         fast  \n",
       "ws train 20220102 num_threads0,batch_size2,num_...     slow  \n",
       "ws train 20220101 num_threads0,batch_size2,num_...     fast  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_stat = {}\n",
    "for fn in fns:\n",
    "    if ' train ' in fn:\n",
    "        dict_stat[fn] = calculate_statistics(fn,dir_log)\n",
    "        \n",
    "for d in dirs:\n",
    "    dict_stat[d] = calculate_statistics(d,dir_log,type_log='d')\n",
    "\n",
    "df_res = pd.DataFrame(dict_stat).T\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "another-reset",
   "metadata": {
    "id": "1c305ede-f5e4-4091-b050-f77041dd3492",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>epochs</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>projected_time_s</th>\n",
       "      <th>projected_time_h</th>\n",
       "      <th>params</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wmla train 20210102 num_threads0,batch_size2,num_workers1 slow.log</th>\n",
       "      <td>74</td>\n",
       "      <td>0-73</td>\n",
       "      <td>517.649</td>\n",
       "      <td>4.23445</td>\n",
       "      <td>512</td>\n",
       "      <td>545</td>\n",
       "      <td>103530</td>\n",
       "      <td>28.7583</td>\n",
       "      <td>num_threads0,batch_size2,num_workers1</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210104 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>21</td>\n",
       "      <td>0-6, 0-6, 0-6</td>\n",
       "      <td>292.381</td>\n",
       "      <td>143.621</td>\n",
       "      <td>207</td>\n",
       "      <td>646</td>\n",
       "      <td>58476.2</td>\n",
       "      <td>16.2434</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210101 num_threads0,batch_size2,num_workers2 slow.log</th>\n",
       "      <td>402</td>\n",
       "      <td>0-200, 0-200</td>\n",
       "      <td>259.107</td>\n",
       "      <td>3.85767</td>\n",
       "      <td>253</td>\n",
       "      <td>298</td>\n",
       "      <td>51821.4</td>\n",
       "      <td>14.3948</td>\n",
       "      <td>num_threads0,batch_size2,num_workers2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210102 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>603</td>\n",
       "      <td>0-200, 0-200, 0-200</td>\n",
       "      <td>176.755</td>\n",
       "      <td>20.863</td>\n",
       "      <td>169</td>\n",
       "      <td>471</td>\n",
       "      <td>35350.9</td>\n",
       "      <td>9.8197</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wmla train 20210103 num_threads0,batch_size2,num_workers3.log</th>\n",
       "      <td>97</td>\n",
       "      <td>0-31, 0-31, 0-32</td>\n",
       "      <td>183.175</td>\n",
       "      <td>50.757</td>\n",
       "      <td>169</td>\n",
       "      <td>470</td>\n",
       "      <td>36635.1</td>\n",
       "      <td>10.1764</td>\n",
       "      <td>num_threads0,batch_size2,num_workers3</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20220102 num_threads0,batch_size2,num_workers1 slow;_5a_xge_8</th>\n",
       "      <td>48</td>\n",
       "      <td>0-47</td>\n",
       "      <td>506.604</td>\n",
       "      <td>4.54945</td>\n",
       "      <td>502</td>\n",
       "      <td>532</td>\n",
       "      <td>101321</td>\n",
       "      <td>28.1447</td>\n",
       "      <td>num_threads0,batch_size2,num_workers1</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20220101 num_threads0,batch_size2,num_workers2 fast;__6vd5hvg</th>\n",
       "      <td>402</td>\n",
       "      <td>0-200, 0-200</td>\n",
       "      <td>259.933</td>\n",
       "      <td>3.68984</td>\n",
       "      <td>251</td>\n",
       "      <td>284</td>\n",
       "      <td>51986.6</td>\n",
       "      <td>14.4407</td>\n",
       "      <td>num_threads0,batch_size2,num_workers2</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   count               epochs  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...    74                 0-73   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...    21        0-6, 0-6, 0-6   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...   402         0-200, 0-200   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...   603  0-200, 0-200, 0-200   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...    97     0-31, 0-31, 0-32   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...    48                 0-47   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...   402         0-200, 0-200   \n",
       "\n",
       "                                                       mean      std  min  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  517.649  4.23445  512   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  292.381  143.621  207   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  259.107  3.85767  253   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  176.755   20.863  169   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  183.175   50.757  169   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  506.604  4.54945  502   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  259.933  3.68984  251   \n",
       "\n",
       "                                                    max projected_time_s  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  545           103530   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  646          58476.2   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  298          51821.4   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  471          35350.9   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  470          36635.1   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  532           101321   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  284          51986.6   \n",
       "\n",
       "                                                   projected_time_h  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...          28.7583   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...          16.2434   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...          14.3948   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...           9.8197   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...          10.1764   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...          28.1447   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...          14.4407   \n",
       "\n",
       "                                                                                   params  \\\n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers1   \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers2   \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  num_threads0,batch_size2,num_workers3   \n",
       "ws train 20220102 num_threads0,batch_size2,num_...  num_threads0,batch_size2,num_workers1   \n",
       "ws train 20220101 num_threads0,batch_size2,num_...  num_threads0,batch_size2,num_workers2   \n",
       "\n",
       "                                                       node  \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...     slow  \n",
       "wmla train 20210104 num_threads0,batch_size2,nu...  unknown  \n",
       "wmla train 20210101 num_threads0,batch_size2,nu...     slow  \n",
       "wmla train 20210102 num_threads0,batch_size2,nu...  unknown  \n",
       "wmla train 20210103 num_threads0,batch_size2,nu...  unknown  \n",
       "ws train 20220102 num_threads0,batch_size2,num_...     slow  \n",
       "ws train 20220101 num_threads0,batch_size2,num_...     fast  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[df_res['params'].str.contains('num_workers')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposed-resort",
   "metadata": {
    "id": "2427e026-e853-47e1-8ff4-aa95890b3cd9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>epochs</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>projected_time_s</th>\n",
       "      <th>projected_time_h</th>\n",
       "      <th>params</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ws train 20211123 gpu2 slow.log</th>\n",
       "      <td>69</td>\n",
       "      <td>0-68</td>\n",
       "      <td>519.87</td>\n",
       "      <td>3.2656</td>\n",
       "      <td>515</td>\n",
       "      <td>533</td>\n",
       "      <td>103974</td>\n",
       "      <td>28.8816</td>\n",
       "      <td>gpu2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211124 gpu2,batch_size4 slow.log</th>\n",
       "      <td>201</td>\n",
       "      <td>0-200</td>\n",
       "      <td>416.1</td>\n",
       "      <td>4.93742</td>\n",
       "      <td>409</td>\n",
       "      <td>453</td>\n",
       "      <td>83219.9</td>\n",
       "      <td>23.1166</td>\n",
       "      <td>gpu2,batch_size4</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211123 batch_size2 slow.log</th>\n",
       "      <td>113</td>\n",
       "      <td>0-112</td>\n",
       "      <td>526.292</td>\n",
       "      <td>3.56403</td>\n",
       "      <td>521</td>\n",
       "      <td>539</td>\n",
       "      <td>105258</td>\n",
       "      <td>29.2384</td>\n",
       "      <td>batch_size2</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211121 num_threads0 fast.log</th>\n",
       "      <td>44</td>\n",
       "      <td>157-200</td>\n",
       "      <td>602.432</td>\n",
       "      <td>4.1253</td>\n",
       "      <td>597</td>\n",
       "      <td>613</td>\n",
       "      <td>120486</td>\n",
       "      <td>33.4684</td>\n",
       "      <td>num_threads0</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211201 num_threads0 fast.log</th>\n",
       "      <td>126</td>\n",
       "      <td>0-125</td>\n",
       "      <td>600.833</td>\n",
       "      <td>4.23281</td>\n",
       "      <td>595</td>\n",
       "      <td>619</td>\n",
       "      <td>120167</td>\n",
       "      <td>33.3796</td>\n",
       "      <td>num_threads0</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ws train 20211124 ??? fast.log</th>\n",
       "      <td>201</td>\n",
       "      <td>0-200</td>\n",
       "      <td>576.299</td>\n",
       "      <td>4.75368</td>\n",
       "      <td>570</td>\n",
       "      <td>616</td>\n",
       "      <td>115260</td>\n",
       "      <td>32.0166</td>\n",
       "      <td>???</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            count   epochs     mean      std  \\\n",
       "ws train 20211123 gpu2 slow.log                69     0-68   519.87   3.2656   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log   201    0-200    416.1  4.93742   \n",
       "ws train 20211123 batch_size2 slow.log        113    0-112  526.292  3.56403   \n",
       "ws train 20211121 num_threads0 fast.log        44  157-200  602.432   4.1253   \n",
       "ws train 20211201 num_threads0 fast.log       126    0-125  600.833  4.23281   \n",
       "ws train 20211124 ??? fast.log                201    0-200  576.299  4.75368   \n",
       "\n",
       "                                             min  max projected_time_s  \\\n",
       "ws train 20211123 gpu2 slow.log              515  533           103974   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log  409  453          83219.9   \n",
       "ws train 20211123 batch_size2 slow.log       521  539           105258   \n",
       "ws train 20211121 num_threads0 fast.log      597  613           120486   \n",
       "ws train 20211201 num_threads0 fast.log      595  619           120167   \n",
       "ws train 20211124 ??? fast.log               570  616           115260   \n",
       "\n",
       "                                            projected_time_h  \\\n",
       "ws train 20211123 gpu2 slow.log                      28.8816   \n",
       "ws train 20211124 gpu2,batch_size4 slow.log          23.1166   \n",
       "ws train 20211123 batch_size2 slow.log               29.2384   \n",
       "ws train 20211121 num_threads0 fast.log              33.4684   \n",
       "ws train 20211201 num_threads0 fast.log              33.3796   \n",
       "ws train 20211124 ??? fast.log                       32.0166   \n",
       "\n",
       "                                                       params  node  \n",
       "ws train 20211123 gpu2 slow.log                          gpu2  slow  \n",
       "ws train 20211124 gpu2,batch_size4 slow.log  gpu2,batch_size4  slow  \n",
       "ws train 20211123 batch_size2 slow.log            batch_size2  slow  \n",
       "ws train 20211121 num_threads0 fast.log          num_threads0  fast  \n",
       "ws train 20211201 num_threads0 fast.log          num_threads0  fast  \n",
       "ws train 20211124 ??? fast.log                            ???  fast  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[~df_res['params'].str.contains('num_workers')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-detroit",
   "metadata": {
    "id": "ef02d1e3-5b55-40f4-96cc-6a19281bcf55"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
